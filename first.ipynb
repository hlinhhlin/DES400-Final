{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the raw data from https://www.kaggle.com/datasets/paololol/league-of-legends-ranked-matches/data?select=stats1.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data obtained from Kaggle is already cleaned, so further cleaning is unnecessary.\n",
    "\n",
    "Due to the large dataset size, the data is divided into two files. We concatenate these files and then merge them with participant data and match data. \n",
    "After merging, we filter the data to include only matches with exactly 10 participants, ensuring that roles are not duplicated within each team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "participant_data = pd.read_csv('./data/participants.csv')\n",
    "stat1_data = pd.read_csv('./data/stats1.csv')\n",
    "stat2_data = pd.read_csv('./data/stats2.csv')\n",
    "matches_data = pd.read_csv('./data/matches.csv')\n",
    "\n",
    "# Concatenate stat1 and stat2\n",
    "merged_stat_data = pd.concat([stat1_data, stat2_data])\n",
    "\n",
    "# Step 1: Merge participant_data with merged_stat_data on 'id'\n",
    "merged_data = pd.merge(participant_data, merged_stat_data, on='id', how='outer')\n",
    "\n",
    "# Step 2: Merge the resulting data with matches_data on 'matchid' and 'id'\n",
    "merged_data = pd.merge(merged_data, matches_data, left_on='matchid', right_on='id', how='inner')\n",
    "\n",
    "# Step 3: Remove the 'id_y' column and rename 'id_x' to 'participantid'\n",
    "merged_data = merged_data.drop(columns=['id_y']).rename(columns={'id_x': 'participantid'})\n",
    "\n",
    "# Step 4: Filter records where dmgtoobj >= dmgtoturrets\n",
    "merged_data = merged_data[\n",
    "    pd.to_numeric(merged_data['dmgtoobj'], errors='coerce') >= pd.to_numeric(merged_data['dmgtoturrets'], errors='coerce')\n",
    "]\n",
    "merged_data = merged_data.dropna(subset=['dmgtoobj', 'dmgtoturrets'])\n",
    "\n",
    "# Step 5: Count the occurrences of each match_id in the filtered merged_data\n",
    "match_id_counts = merged_data['matchid'].value_counts()\n",
    "\n",
    "# Step 6: Find match_ids that appear exactly 10 times\n",
    "match_ids_with_10_records = match_id_counts[match_id_counts == 10].index\n",
    "\n",
    "# Step 7: Filter merged_data to include only those records where the match_id appears 10 times\n",
    "participants_with_10_records = merged_data[merged_data['matchid'].isin(match_ids_with_10_records)]\n",
    "\n",
    "# Step 8: Define conditions for assigning roles\n",
    "conditions = [\n",
    "    (participants_with_10_records['role'] == 'SOLO') & (participants_with_10_records['position'] == 'TOP'),\n",
    "    (participants_with_10_records['role'] == 'NONE') & (participants_with_10_records['position'] == 'JUNGLE'),\n",
    "    (participants_with_10_records['role'] == 'SOLO') & (participants_with_10_records['position'] == 'MID'),\n",
    "    (participants_with_10_records['role'] == 'DUO_CARRY') & (participants_with_10_records['position'] == 'BOT'),\n",
    "    (participants_with_10_records['role'] == 'DUO_SUPPORT') & (participants_with_10_records['position'] == 'BOT')\n",
    "]\n",
    "\n",
    "# Define the corresponding values for each condition\n",
    "values = ['TOP', 'JUNGLE', 'MID', 'ADC', 'SUPPORT']\n",
    "\n",
    "# Create a new column 'role_position' and apply the conditions\n",
    "participants_with_10_records['role_position'] = np.select(conditions, values, default='UNKNOWN')\n",
    "\n",
    "# Step 9: Check each match_id to ensure both teams have exactly 5 unique roles\n",
    "valid_matches = []\n",
    "\n",
    "# Loop through each match_id\n",
    "for match_id in match_ids_with_10_records:\n",
    "    # Get the participants for this match\n",
    "    match_participants = participants_with_10_records[participants_with_10_records['matchid'] == match_id]\n",
    "    \n",
    "    # Split participants by their win/loss (1 = win, 0 = loss)\n",
    "    team1 = match_participants[match_participants['win'] == 1]\n",
    "    team2 = match_participants[match_participants['win'] == 0]\n",
    "    \n",
    "    # Ensure both teams have exactly 5 players and 5 unique roles\n",
    "    if len(team1) == 5 and len(team2) == 5:\n",
    "        if len(team1['role_position'].unique()) == 5 and len(team2['role_position'].unique()) == 5:\n",
    "            valid_matches.append(match_id)\n",
    "\n",
    "# Step 10: Filter the merged_data again to keep only valid matches\n",
    "valid_participants = participants_with_10_records[participants_with_10_records['matchid'].isin(valid_matches)]\n",
    "\n",
    "print(valid_participants.shape)\n",
    "\n",
    "# Step 11: Save the result to a new CSV file\n",
    "# valid_participants.to_csv('../data/new/parti10records_unique_role.csv', index=False)\n",
    "\n",
    "print(f\"Number of valid matches with exactly 5 unique roles per team based on win/loss: {len(valid_matches)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter the columns to reduce the dataset size while retaining an overview of key metrics for each role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the columns you want to keep\n",
    "columns_to_keep = [\n",
    "    'participantid', 'matchid', 'championid', 'win', 'kills', 'deaths', 'assists', 'largestkillingspree', 'largestmultikill', \n",
    "    'killingsprees', 'doublekills', 'triplekills', 'quadrakills', 'pentakills', 'legendarykills',\n",
    "    'totdmgdealt', 'totdmgtochamp', 'dmgtoobj', 'visionscore', 'totdmgtaken', 'goldearned', 'inhibkills', \n",
    "    'totminionskilled', 'neutralminionskilled', 'wardsbought', 'wardsplaced', 'wardskilled', 'role_position', 'duration', 'dmgtoturrets'\n",
    "]\n",
    "\n",
    "# Filter the data\n",
    "filtered_data = valid_participants[columns_to_keep]\n",
    "\n",
    "print(filtered_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate the dataset into subsets based on each role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_laners_df = filtered_data[filtered_data['role_position'] == 'TOP']\n",
    "junglers_df = filtered_data[filtered_data['role_position'] == 'JUNGLE']\n",
    "mid_laners_df = filtered_data[filtered_data['role_position'] == 'MID']\n",
    "adc_df = filtered_data[filtered_data['role_position'] == 'ADC']\n",
    "supports_df = filtered_data[filtered_data['role_position'] == 'SUPPORT']\n",
    "\n",
    "print(top_laners_df.shape)\n",
    "print(junglers_df.shape)\n",
    "print(mid_laners_df.shape)\n",
    "print(adc_df.shape)\n",
    "print(supports_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Higher Death, Less Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to make the 'deaths' column negative\n",
    "def make_column_negative(df, column_name='deaths'):\n",
    "    if column_name in df.columns:\n",
    "        df[column_name] = -df[column_name]\n",
    "    return df\n",
    "\n",
    "# Apply the function to each role-specific DataFrame\n",
    "top_laners_df = make_column_negative(filtered_data[filtered_data['role_position'] == 'TOP'])\n",
    "junglers_df = make_column_negative(filtered_data[filtered_data['role_position'] == 'JUNGLE'])\n",
    "mid_laners_df = make_column_negative(filtered_data[filtered_data['role_position'] == 'MID'])\n",
    "adc_df = make_column_negative(filtered_data[filtered_data['role_position'] == 'ADC'])\n",
    "supports_df = make_column_negative(filtered_data[filtered_data['role_position'] == 'SUPPORT'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metric Transformation by dividing with duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match_duration_col = 'duration'  # Column that contains match duration (in seconds or minutes)\n",
    "\n",
    "def divide_by_duration(df, metrics, suffix='_per_minute'):\n",
    "    df['duration'] = df['duration'] / 60\n",
    "    for metric in metrics:\n",
    "        # Convert match duration to minutes (if it's in seconds)\n",
    "        # Create a new column with the suffix to store the divided value\n",
    "        new_column_name = metric + suffix\n",
    "        df[new_column_name] = df[metric] / df['duration']\n",
    "    return df\n",
    "\n",
    "\n",
    "def generate_dmg_per_kill(df, dmg_col='totdmgtochamp', kills_col='kills', new_feature_name='dmg_per_kill'):\n",
    "    # Create the new feature by dividing totdmgtochamp by kills\n",
    "    df[new_feature_name] = df[dmg_col] / df[kills_col]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def generate_visionscore_per_wardplaced(df, visionscore_col='visionscore', wardsplaced_col='wardsplaced', new_feature_name='visionscore_per_wardplaced'):\n",
    "    # Create the new feature by dividing visionscore by wardsplaced\n",
    "    df[new_feature_name] = df[visionscore_col] / df[wardsplaced_col]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def fill_wardsbought_with_average(df):\n",
    "    # Replace non-numeric entries (e.g., '\\N') with NaN\n",
    "    df['wardsbought'].replace('\\\\N', np.nan, inplace=True)\n",
    "    \n",
    "    # Convert to numeric, coercing any remaining non-numeric values to NaN\n",
    "    df['wardsbought'] = pd.to_numeric(df['wardsbought'], errors='coerce')\n",
    "    \n",
    "    # Calculate the average, ignoring NaN\n",
    "    average_wardsbought = df['wardsbought'].mean()\n",
    "    \n",
    "    # Fill NaN values with the average\n",
    "    df['wardsbought'].fillna(average_wardsbought, inplace=True)\n",
    "    \n",
    "    # Ensure the column is of numeric type (float)\n",
    "    df['wardsbought'] = df['wardsbought'].astype(float)\n",
    "    # print(df['wardsbought'].head())\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Special Handle for Support due to 'wardplaced' is Object (it cannot be divided by float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Role\n",
    "support_fill_nan_data = fill_wardsbought_with_average(supports_df)\n",
    "support_metrics_to_divide = ['visionscore', 'wardsplaced', 'wardskilled', 'wardsbought', 'totdmgtaken', 'kills', 'deaths', 'assists']\n",
    "# support_visionscore_per_wardplaced = generate_visionscore_per_wardplaced(support_fill_nan_data)\n",
    "\n",
    "# print(support_visionscore_per_wardplaced['wardsbought'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for column in support_metrics_to_divide:\n",
    "#     if column in support_visionscore_per_wardplaced.columns:\n",
    "#         print(f\"{column}: {support_visionscore_per_wardplaced[column].dtype}\")\n",
    "#     else:\n",
    "#         print(f\"{column}: Column not found in DataFrame\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADC Role\n",
    "adc_metrics_to_divide = ['totdmgtochamp', 'totminionskilled', 'dmgtoobj', 'goldearned', 'kills', 'deaths', 'assists', 'dmgtoturrets']\n",
    "adc_divided = divide_by_duration(adc_df, adc_metrics_to_divide)\n",
    "\n",
    "support_divided = divide_by_duration(support_fill_nan_data, support_metrics_to_divide)\n",
    "\n",
    "# Mid Role\n",
    "mid_metrics_to_divide = ['totdmgtochamp', 'goldearned','visionscore', 'dmgtoobj', 'totdmgdealt','totminionskilled', 'kills', 'deaths', 'assists']\n",
    "mid_divided = divide_by_duration(mid_laners_df, mid_metrics_to_divide)\n",
    "\n",
    "# Top Role\n",
    "top_metrics_to_divide = ['totdmgtaken', 'deaths', 'assists', 'goldearned', 'totdmgtochamp', 'totminionskilled', 'totdmgdealt', 'kills']\n",
    "top_damage_per_kill = generate_dmg_per_kill(top_laners_df)\n",
    "top_divided = divide_by_duration(top_damage_per_kill, top_metrics_to_divide)\n",
    "\n",
    "# Jungle Role\n",
    "jungle_metrics_to_divide = ['neutralminionskilled', 'kills', 'assists', 'goldearned','visionscore', 'totdmgdealt', 'dmgtoobj', 'totdmgtochamp', 'deaths']\n",
    "jungle_divided = divide_by_duration(junglers_df, jungle_metrics_to_divide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(mid_divided.head())\n",
    "print(adc_divided.shape)\n",
    "print(jungle_divided.shape)\n",
    "print(support_divided.shape)\n",
    "print(mid_divided.shape)\n",
    "print(top_divided.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding Feature Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_correlation_matrix(df, features, role_name):\n",
    "    # Combine tiers\n",
    "    metrics = df[features]\n",
    "\n",
    "    # Check for columns with string values and report them\n",
    "    non_numeric_columns = metrics.select_dtypes(include=['object']).columns\n",
    "    if not non_numeric_columns.empty:\n",
    "        print(f\"Warning: The following columns in {role_name} contain non-numeric data:\")\n",
    "        print(non_numeric_columns)\n",
    "        for col in non_numeric_columns:\n",
    "            print(f\"Non-numeric values in '{col}':\")\n",
    "            print(metrics[col].unique())\n",
    "\n",
    "    # Convert all columns to numeric, forcing errors to NaN\n",
    "    metrics = metrics.apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    # Drop rows with NaN values\n",
    "    metrics = metrics.dropna()\n",
    "\n",
    "    # Calculate correlation matrix\n",
    "    correlation_matrix = metrics.corr()\n",
    "\n",
    "    # Visualize the correlation matrix using a heatmap\n",
    "    plt.figure(figsize=(12, 10))  # Increase figure size to give more space for labels\n",
    "    heatmap = sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "    \n",
    "    # Set the title of the heatmap\n",
    "    plt.title(f'Correlation Matrix for {role_name} Features')\n",
    "    \n",
    "    # Adjust layout to avoid cutting off labels\n",
    "    plt.subplots_adjust(left=0.25, right=0.9, top=0.9, bottom=0.25)  # Adjust both left and bottom margins\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the heatmap showing the correlation of the features (after first consideration based on team's domain knowledge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_before_correlation_metrics = {\n",
    "    \"adc\": ['totdmgtochamp_per_minute', 'totminionskilled_per_minute', 'goldearned_per_minute', 'largestkillingspree', 'largestmultikill', 'dmgtoobj_per_minute', 'kills_per_minute', 'deaths_per_minute', 'assists_per_minute', 'dmgtoturrets_per_minute'],\n",
    "    \"support\": ['wardskilled_per_minute', 'wardsplaced_per_minute', 'visionscore_per_minute', 'wardsbought_per_minute', 'totdmgtaken_per_minute', 'kills_per_minute', 'deaths_per_minute', 'assists_per_minute'],\n",
    "    \"mid\": ['totdmgtochamp_per_minute', 'goldearned_per_minute', 'largestkillingspree', 'visionscore_per_minute', 'totdmgdealt_per_minute', 'dmgtoobj_per_minute', 'totminionskilled_per_minute', 'kills_per_minute', 'deaths_per_minute', 'assists_per_minute'],\n",
    "    \"top\": ['totdmgtaken_per_minute', 'deaths_per_minute', 'dmg_per_kill', 'goldearned_per_minute', 'totdmgtochamp_per_minute', 'assists_per_minute', 'totminionskilled_per_minute', 'totdmgdealt_per_minute', 'kills_per_minute', 'largestkillingspree'],\n",
    "    \"jungle\": ['neutralminionskilled_per_minute', 'kills_per_minute', 'assists_per_minute', 'goldearned_per_minute', 'visionscore_per_minute', 'totdmgdealt_per_minute', 'dmgtoobj_per_minute', 'totdmgtochamp_per_minute', 'killingsprees', 'largestmultikill', 'deaths_per_minute']\n",
    "}\n",
    "\n",
    "visualize_correlation_matrix(adc_divided, normalized_before_correlation_metrics['adc'], 'ADC')\n",
    "visualize_correlation_matrix(support_divided, normalized_before_correlation_metrics['support'], 'Support')\n",
    "visualize_correlation_matrix(mid_divided, normalized_before_correlation_metrics['mid'], 'Mid')\n",
    "visualize_correlation_matrix(top_divided, normalized_before_correlation_metrics['top'], 'Top')\n",
    "visualize_correlation_matrix(jungle_divided, normalized_before_correlation_metrics['jungle'], 'Jungle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the feature pairs having high correlation and plot the heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(adc_divided.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_after_correlation_metrics = {\n",
    "    \"adc\": ['totdmgtochamp_per_minute', 'totminionskilled_per_minute', 'largestkillingspree', 'largestmultikill', 'dmgtoobj_per_minute', 'deaths_per_minute', 'assists_per_minute', 'dmgtoturrets_per_minute'],\n",
    "    \"support\": ['wardskilled_per_minute', 'wardsplaced_per_minute', 'visionscore_per_minute', 'wardsbought_per_minute', 'totdmgtaken_per_minute', 'kills_per_minute', 'deaths_per_minute', 'assists_per_minute'],    \n",
    "    \"mid\": ['totdmgtochamp_per_minute', 'visionscore_per_minute', 'totdmgdealt_per_minute', 'dmgtoobj_per_minute', 'totminionskilled_per_minute', 'kills_per_minute', 'deaths_per_minute', 'assists_per_minute'],\n",
    "    \"top\": ['totdmgtaken_per_minute', 'deaths_per_minute', 'dmg_per_kill', 'totdmgtochamp_per_minute', 'assists_per_minute', 'totdmgdealt_per_minute', 'kills_per_minute', 'totminionskilled_per_minute'],\n",
    "    \"jungle\": ['neutralminionskilled_per_minute', 'kills_per_minute', 'assists_per_minute', 'visionscore_per_minute', 'totdmgdealt_per_minute', 'dmgtoobj_per_minute', 'totdmgtochamp_per_minute', 'largestmultikill', 'deaths_per_minute']\n",
    "}\n",
    "\n",
    "visualize_correlation_matrix(adc_divided, normalized_after_correlation_metrics['adc'], 'ADC')\n",
    "visualize_correlation_matrix(support_divided, normalized_after_correlation_metrics['support'], 'Support')\n",
    "visualize_correlation_matrix(mid_divided, normalized_after_correlation_metrics['mid'], 'Mid')\n",
    "visualize_correlation_matrix(top_divided, normalized_after_correlation_metrics['top'], 'Top')\n",
    "visualize_correlation_matrix(jungle_divided, normalized_after_correlation_metrics['jungle'], 'Jungle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ADC\", len(adc_divided))\n",
    "print(\"Support\", len(support_divided))\n",
    "print(\"Mid\", len(mid_divided))\n",
    "print(\"Top\", len(top_divided))\n",
    "print(\"Jungle\", len(jungle_divided))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(adc_divided['duration'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_for_plot = {\n",
    "    0: 'orange',\n",
    "    1: 'red',\n",
    "    2: 'blue',\n",
    "    3: 'green',\n",
    "    4: 'purple',\n",
    "    5: 'brown',\n",
    "    6: 'pink',\n",
    "    7: 'gray',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import itertools\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Inertia = measure of cluster compactness\n",
    "# lower values = data points are closer to their centroids\n",
    "# meaning clusters are more compact, well-defined.\n",
    "\n",
    "# In the elbow method, plot the inertia values against the number of clusters 𝑘\n",
    "# As k increases, inertia decreases \n",
    "# adding more clusters reduces the average distance between data points and their cluster centers.\n",
    "\n",
    "# The elbow point = the point where the inertia starts decreasing at a slower rate, \n",
    "# forming an elbow in the plot.\n",
    "# The elbow point = Ideal number of clusters because \n",
    "# Balances compact clusters + avoiding over-segmentation\n",
    "\n",
    "def plot_elbow_silhouette(df, features, role):\n",
    "    X_scaled = StandardScaler().fit_transform(df[features])\n",
    "    # X_scaled = MinMaxScaler().fit_transform(df[features])\n",
    "    max_clusters = 10\n",
    "    inertia_values, silhouette_values = [], []\n",
    "    # generates a sequence of integers from 2 to max_clusters (inclusive) (cluster 2 to 10)\n",
    "    cluster_range = range(2, max_clusters + 1)\n",
    "\n",
    "    for k in cluster_range:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        labels = kmeans.fit_predict(df[features])\n",
    "        inertia_values.append(kmeans.inertia_)\n",
    "        silhouette_values.append(silhouette_score(df[features], labels))\n",
    "\n",
    "    # Elbow plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(cluster_range, inertia_values, 'bo-')\n",
    "    plt.title(f'{role.capitalize()} Elbow Plot')\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('Inertia (within cluster sum of squares)')\n",
    "\n",
    "    # Silhouette plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(cluster_range, silhouette_values, 'go-')\n",
    "    plt.title(f'{role.capitalize()} Silhouette Score Plot')\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('Silhouette Score')\n",
    "\n",
    "    plt.suptitle(f'Elbow and Silhouette Analysis for {role.capitalize()} Role')\n",
    "    plt.show()\n",
    "    # plt.savefig(f\"./Isolation-forest-getInsight/Elbow-silhouette/{role}_elbow_silhouette_plot.png\", dpi=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isolation_forest_plot_elbow_silhouette(role, data_role):\n",
    "    print(f\"Processing role: {role}\")\n",
    "    \n",
    "    # Drop unnecessary columns\n",
    "    df = data_role.drop(columns=['wardsbought', 'role_position'], errors='ignore')\n",
    "    \n",
    "    # Select features and preprocess\n",
    "    features = normalized_after_correlation_metrics[role]\n",
    "    X = df[features].apply(pd.to_numeric, errors='coerce').dropna()\n",
    "    X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    X = np.clip(X, a_min=-1e5, a_max=1e5).dropna()\n",
    "    df = df.loc[X.index]\n",
    "\n",
    "    # Scale data\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Isolation Forest\n",
    "    iso_forest = IsolationForest(contamination=0.01, random_state=42)\n",
    "    df['anomaly'] = iso_forest.fit_predict(X_scaled)\n",
    "    anomaly_data = df[df['anomaly'] == -1]\n",
    "    normal_data = df[df['anomaly'] != -1]\n",
    "\n",
    "    # Plot elbow and silhouette for anomaly data\n",
    "    plot_elbow_silhouette(anomaly_data, features, role)\n",
    "\n",
    "    # Plot normal vs anomaly data\n",
    "    plot_normal_vs_anomaly(normal_data, anomaly_data, features, role)\n",
    "\n",
    "    return anomaly_data, normal_data\n",
    "\n",
    "\n",
    "def plot_normal_vs_anomaly(normal_data, anomaly_data, features, role):\n",
    "    \"\"\"\n",
    "    Plots normal (blue) and anomaly (red) data points for all feature combinations.\n",
    "\n",
    "    Args:\n",
    "        normal_data (DataFrame): Data classified as normal.\n",
    "        anomaly_data (DataFrame): Data classified as anomalies.\n",
    "        features (list): List of feature columns.\n",
    "        role (str): Role name for the plot title.\n",
    "        alpha_normal (float): Transparency level for normal data points (default: 0.4).\n",
    "        alpha_anomaly (float): Transparency level for anomaly data points (default: 0.6).\n",
    "    \"\"\"\n",
    "    import itertools\n",
    "\n",
    "    # Generate feature combinations for scatter plots\n",
    "    feature_combinations = list(itertools.combinations(features, 2))\n",
    "    n_cols = 4\n",
    "    n_rows = (len(feature_combinations) + n_cols - 1) // n_cols\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(18, n_rows * 3))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, (feature_x, feature_y) in enumerate(feature_combinations):\n",
    "        ax = axes[i]\n",
    "\n",
    "        # Plot normal data points (blue, customizable alpha)\n",
    "        ax.scatter(\n",
    "            normal_data[feature_x], \n",
    "            normal_data[feature_y], \n",
    "            c='blue', \n",
    "            label='Normal', \n",
    "            alpha=0.2\n",
    "        )\n",
    "\n",
    "        # Plot anomaly data points (red, customizable alpha)\n",
    "        ax.scatter(\n",
    "            anomaly_data[feature_x], \n",
    "            anomaly_data[feature_y], \n",
    "            c='red', \n",
    "            label='Anomaly', \n",
    "            alpha=0.2\n",
    "        )\n",
    "\n",
    "        # Add labels and title\n",
    "        ax.set_title(f'{feature_x} vs {feature_y}', fontsize=8)\n",
    "        ax.set_xlabel(feature_x, fontsize=8)\n",
    "        ax.set_ylabel(feature_y, fontsize=8)\n",
    "\n",
    "    # Remove extra subplots if any\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    fig.suptitle(f'Normal vs Anomaly Plot for {role.capitalize()} Role', fontsize=16)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(adc_include_anomaly, adc_normal) = isolation_forest_plot_elbow_silhouette('adc', adc_divided)\n",
    "(support_include_anomaly, support_normal) = isolation_forest_plot_elbow_silhouette('support', support_divided)\n",
    "(mid_include_anomaly, mid_normal) = isolation_forest_plot_elbow_silhouette('mid', mid_divided)    \n",
    "(top_include_anomaly, top_normal) = isolation_forest_plot_elbow_silhouette('top', top_divided)\n",
    "(jungle_include_anomaly, jungle_normal) = isolation_forest_plot_elbow_silhouette('jungle', jungle_divided)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_outliers_with_kmeans(outliers_df, features, role, n_clusters):\n",
    "    scaler = StandardScaler()\n",
    "    X_outliers_scaled = scaler.fit_transform(outliers_df[features])\n",
    "\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    outliers_df['kmeans_cluster'] = kmeans.fit_predict(X_outliers_scaled)\n",
    "        \n",
    "    plot_clusters(outliers_df, features, f\"{role.capitalize()} KMeans Cluster Analysis with {n_clusters} Clusters\")\n",
    "\n",
    "    for cluster in outliers_df['kmeans_cluster'].unique():\n",
    "        plot_each_cluster(outliers_df, features, cluster, f\"{role.capitalize()} KMeans Cluster Analysis with {n_clusters} Clusters\")\n",
    "        \n",
    "    return outliers_df\n",
    "\n",
    "def plot_clusters(df, features, title):\n",
    "    feature_combinations = list(itertools.combinations(features, 2))\n",
    "    n_cols = 4\n",
    "    n_rows = (len(feature_combinations) + n_cols - 1) // n_cols\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(18, n_rows * 3))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, (feature_x, feature_y) in enumerate(feature_combinations):\n",
    "        ax = axes[i]\n",
    "        for cluster in df['kmeans_cluster'].unique():\n",
    "            cluster_data = df[df['kmeans_cluster'] == cluster]\n",
    "            cluster_color = color_for_plot.get(cluster, 'gray')  # Default to 'gray' if cluster color is not defined\n",
    "            ax.scatter(cluster_data[feature_x], cluster_data[feature_y], label=f'Cluster {cluster}', color=cluster_color, alpha=0.5)\n",
    "        ax.set_title(f'{feature_x} vs {feature_y}', fontsize=8)\n",
    "        ax.set_xlabel(feature_x, fontsize=8)\n",
    "        ax.set_ylabel(feature_y, fontsize=8)\n",
    "\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_each_cluster(df, features, cluster, title):\n",
    "    cluster_data = df[df['kmeans_cluster'] == cluster]\n",
    "    print(f\"Cluster {cluster}: {len(cluster_data)} data points\")\n",
    "    feature_combinations = list(itertools.combinations(features, 2))\n",
    "    n_cols = 4\n",
    "    n_rows = (len(feature_combinations) + n_cols - 1) // n_cols\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(18, n_rows * 3))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, (feature_x, feature_y) in enumerate(feature_combinations):\n",
    "        ax = axes[i]\n",
    "        cluster_color = color_for_plot.get(cluster, 'gray')  # Default to 'gray' if cluster color is not defined\n",
    "        ax.scatter(cluster_data[feature_x], cluster_data[feature_y], color=cluster_color, alpha=0.5)\n",
    "        ax.set_title(f'{feature_x} vs {feature_y}', fontsize=8)\n",
    "        ax.set_xlabel(feature_x, fontsize=8)\n",
    "        ax.set_ylabel(feature_y, fontsize=8)\n",
    "\n",
    "    # Remove unused subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "    \n",
    "    fig.suptitle(f'{title} - Cluster {cluster}', fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# role_cluster_counts = {'adc': 3, 'support': 6 , 'mid': 5, 'top': 5, 'jungle': 5}\n",
    "\n",
    "# adc_cluster_counts = 3\n",
    "# support_cluster_counts = 6\n",
    "# mid_cluster_counts =5\n",
    "# top_cluster_counts = 5\n",
    "# jungle_cluster_counts = 5\n",
    "\n",
    "adc_cluster_counts = 4\n",
    "support_cluster_counts = 4\n",
    "mid_cluster_counts = 4\n",
    "top_cluster_counts = 5\n",
    "jungle_cluster_counts = 5\n",
    "\n",
    "adc_outlier_kmean = analyze_outliers_with_kmeans(adc_include_anomaly, normalized_before_correlation_metrics['adc'], 'adc', adc_cluster_counts)\n",
    "support_outlier_kmean = analyze_outliers_with_kmeans(support_include_anomaly, normalized_before_correlation_metrics['support'], 'support', support_cluster_counts)\n",
    "mid_outlier_kmean = analyze_outliers_with_kmeans(mid_include_anomaly, normalized_before_correlation_metrics['mid'], 'mid', mid_cluster_counts)\n",
    "top_outlier_kmean = analyze_outliers_with_kmeans(top_include_anomaly, normalized_before_correlation_metrics['top'], 'top', top_cluster_counts)\n",
    "jungle_outlier_kmean = analyze_outliers_with_kmeans(jungle_include_anomaly, normalized_before_correlation_metrics['jungle'], 'jungle', jungle_cluster_counts)\n",
    "\n",
    "# print(len(adc_outlier_kmean))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_features(df, feature_cols):\n",
    "    \"\"\"\n",
    "    Normalize features to the range [0, 1].\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The input dataframe.\n",
    "        feature_cols (list): List of columns to normalize.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A dataframe with normalized features.\n",
    "    \"\"\"\n",
    "    df_normalized = df.copy()\n",
    "    for col in feature_cols:\n",
    "        min_val = df[col].min()\n",
    "        max_val = df[col].max()\n",
    "        df_normalized[col] = (df[col] - min_val) / (max_val - min_val)\n",
    "    return df_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zscore_plot_normalized(df, cluster_col, feature_cols, role):\n",
    "    # Normalize the selected features\n",
    "    df_normalized = normalize_features(df, feature_cols)\n",
    "\n",
    "    # Combine normalized scores by summing across features\n",
    "    df_normalized['normalized_score_combined'] = df_normalized[feature_cols].sum(axis=1)\n",
    "\n",
    "    # Ensure the index is a range index for consistent plotting\n",
    "    df = df.reset_index(drop=True)\n",
    "    df_normalized = df_normalized.reset_index(drop=True)\n",
    "\n",
    "    # Scatter plot by cluster\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    unique_clusters = df[cluster_col].unique()\n",
    "\n",
    "    for cluster in unique_clusters:\n",
    "        cluster_data = df[df[cluster_col] == cluster]\n",
    "        color = color_for_plot.get(cluster, 'gray')  # Default to gray if cluster color is not defined\n",
    "        plt.scatter(\n",
    "            cluster_data.index,\n",
    "            df_normalized.loc[cluster_data.index, 'normalized_score_combined'],\n",
    "            label=f'Cluster {cluster}',\n",
    "            color=color,\n",
    "            alpha=0.7\n",
    "        )\n",
    "    \n",
    "    plt.title(f'Normalized Metrics Plot by Cluster {role.capitalize()}')\n",
    "    plt.xlabel('Record Index')\n",
    "    plt.ylabel('Normalized Combined Score')\n",
    "    plt.legend()\n",
    "    # plt.savefig(f\"action/initial-plot/cross-validation/plot/{role}_normalized_zscore.png\", dpi=100)\n",
    "\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(adc_outlier_kmean))\n",
    "print(len(mid_outlier_kmean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zscore_plot_normalized(adc_outlier_kmean, 'kmeans_cluster', normalized_after_correlation_metrics['adc'], 'ADC')\n",
    "zscore_plot_normalized(support_outlier_kmean, 'kmeans_cluster', normalized_after_correlation_metrics['support'], 'Support')\n",
    "zscore_plot_normalized(mid_outlier_kmean, 'kmeans_cluster', normalized_after_correlation_metrics['mid'], 'Mid')\n",
    "zscore_plot_normalized(top_outlier_kmean, 'kmeans_cluster', normalized_after_correlation_metrics['top'], 'Top')\n",
    "zscore_plot_normalized(jungle_outlier_kmean, 'kmeans_cluster', normalized_after_correlation_metrics['jungle'], 'Jungle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_role_data(df, feature_cols, thresholds=None):\n",
    "    df_normalized = normalize_features(df, feature_cols)\n",
    "\n",
    "    print(df_normalized.head())\n",
    "\n",
    "    # Combine normalized scores by summing across features\n",
    "    df_normalized['normalized_score_combined'] = df_normalized[feature_cols].sum(axis=1)\n",
    "\n",
    "    # Drop rows with NaN values\n",
    "    df_normalized = df_normalized.dropna(subset=feature_cols)\n",
    "\n",
    "    overall_performance = df_normalized['normalized_score_combined']\n",
    "    \n",
    "    # Create histogram\n",
    "    bins = np.linspace(overall_performance.min(), overall_performance.max(), 50)\n",
    "    counts, edges = np.histogram(overall_performance, bins=bins)\n",
    "\n",
    "    # Plot the histogram\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(edges[:-1], counts, width=np.diff(edges), color='skyblue', edgecolor='black')\n",
    "\n",
    "    # Process thresholds if provided\n",
    "    outliers_count = {}\n",
    "    if thresholds:\n",
    "        for idx, threshold in enumerate(thresholds):\n",
    "            threshold_value = overall_performance.mean() + threshold * overall_performance.std()\n",
    "            \n",
    "            # Identify outliers\n",
    "            outliers = df_normalized[overall_performance > threshold_value]\n",
    "            outliers_count[threshold] = len(outliers)\n",
    "\n",
    "            # Plot the threshold line\n",
    "            plt.axvline(threshold_value, color='red', linestyle='dashed', linewidth=1, label=f'Threshold {threshold}')\n",
    "            vertical_offset = 0.9 - idx * 0.1  # Adjust vertical position for each threshold\n",
    "            plt.text(threshold_value, max(counts) * vertical_offset, f'Threshold {threshold}', color='red', rotation=45, ha='right')\n",
    "\n",
    "        # Annotate the number of outliers for each threshold\n",
    "        annotation_text = \"\\n\".join([f\"Threshold {threshold}: {count} outliers\" for threshold, count in outliers_count.items()])\n",
    "        plt.text(overall_performance.max() * 0.95, max(counts) * 0.8, annotation_text, fontsize=10,\n",
    "                 bbox=dict(facecolor='white', alpha=0.7), ha='right', va='top')\n",
    "\n",
    "        # Print outliers for each threshold\n",
    "        for threshold, count in outliers_count.items():\n",
    "            print(f\"Outliers at threshold {threshold}: {count} outliers\")\n",
    "            print(f\"It is about {count / len(df) * 100:.2f}% of the total data\")\n",
    "    else:\n",
    "        print(\"No thresholds provided, skipping outlier calculation.\")\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel('Overall Performance Score')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Performance Distribution {(\"(Thresholds: \" + str(thresholds) + \")\") if thresholds else \"\"}')\n",
    "    plt.legend(loc='upper right' if thresholds else None)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return overall_performance\n",
    "\n",
    "\n",
    "# Define thresholds for detecting outliers\n",
    "thresholds = [2, 2.5, 3, 3.5]\n",
    "\n",
    "process_role_data(adc_divided, normalized_after_correlation_metrics['adc'], thresholds)\n",
    "process_role_data(support_divided, normalized_after_correlation_metrics['support'], thresholds)\n",
    "process_role_data(mid_divided, normalized_after_correlation_metrics['mid'], thresholds)\n",
    "process_role_data(top_divided, normalized_after_correlation_metrics['top'], thresholds)\n",
    "process_role_data(jungle_divided, normalized_after_correlation_metrics['jungle'], thresholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the z-score distribution for normal data detected by isolation forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_role_data(adc_outlier_kmean, normalized_after_correlation_metrics['adc'])\n",
    "process_role_data(support_outlier_kmean, normalized_after_correlation_metrics['support'])\n",
    "process_role_data(mid_outlier_kmean, normalized_after_correlation_metrics['mid'])\n",
    "process_role_data(top_outlier_kmean, normalized_after_correlation_metrics['top'])\n",
    "process_role_data(jungle_outlier_kmean, normalized_after_correlation_metrics['jungle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_role_data(adc_normal, normalized_after_correlation_metrics['adc'])\n",
    "process_role_data(support_normal, normalized_after_correlation_metrics['support'])\n",
    "process_role_data(mid_normal, normalized_after_correlation_metrics['mid'])\n",
    "process_role_data(top_normal, normalized_after_correlation_metrics['top'])\n",
    "process_role_data(jungle_normal, normalized_after_correlation_metrics['jungle'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
