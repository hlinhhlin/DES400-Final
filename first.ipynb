{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the raw data from https://www.kaggle.com/datasets/paololol/league-of-legends-ranked-matches/data?select=stats1.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data obtained from Kaggle is already cleaned, so further cleaning is unnecessary.\n",
    "\n",
    "Due to the large dataset size, the data is divided into two files. We concatenate these files and then merge them with participant data and match data. \n",
    "After merging, we filter the data to include only matches with exactly 10 participants, ensuring that roles are not duplicated within each team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dw/x19hnlxd69lg2jy91nlhkxrm0000gn/T/ipykernel_65013/852831567.py:7: DtypeWarning: Columns (52) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  stat2_data = pd.read_csv('./data/raw/stats2.csv')\n",
      "/var/folders/dw/x19hnlxd69lg2jy91nlhkxrm0000gn/T/ipykernel_65013/852831567.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  participants_with_10_records['role_position'] = np.select(conditions, values, default='UNKNOWN')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 52\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Loop through each match_id\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m match_id \u001b[38;5;129;01min\u001b[39;00m match_ids_with_10_records:\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;66;03m# Get the participants for this match\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m     match_participants \u001b[38;5;241m=\u001b[39m participants_with_10_records[\u001b[43mparticipants_with_10_records\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmatchid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmatch_id\u001b[49m]\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;66;03m# Split participants by their win/loss (1 = win, 0 = loss)\u001b[39;00m\n\u001b[1;32m     55\u001b[0m     team1 \u001b[38;5;241m=\u001b[39m match_participants[match_participants[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwin\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/ops/common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/arraylike.py:40\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/series.py:6119\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6116\u001b[0m lvalues \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   6117\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 6119\u001b[0m res_values \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/ops/array_ops.py:347\u001b[0m, in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    344\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m comp_method_OBJECT_ARRAY(op, lvalues, rvalues)\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 347\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43m_na_arithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_cmp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res_values\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/ops/array_ops.py:218\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[0;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[1;32m    215\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(expressions\u001b[38;5;241m.\u001b[39mevaluate, op)\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 218\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cmp \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m    221\u001b[0m         left\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(right, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m\n\u001b[1;32m    222\u001b[0m     ):\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;66;03m# Don't do this for comparisons, as that will handle complex numbers\u001b[39;00m\n\u001b[1;32m    226\u001b[0m         \u001b[38;5;66;03m#  incorrectly, see GH#32047\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/computation/expressions.py:242\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m op_str \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_numexpr:\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;66;03m# error: \"None\" not callable\u001b[39;00m\n\u001b[0;32m--> 242\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/computation/expressions.py:73\u001b[0m, in \u001b[0;36m_evaluate_standard\u001b[0;34m(op, op_str, a, b)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _TEST_MODE:\n\u001b[1;32m     72\u001b[0m     _store_test_result(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "participant_data = pd.read_csv('./data/raw/participants.csv')\n",
    "stat1_data = pd.read_csv('./data/raw/stats1.csv')\n",
    "stat2_data = pd.read_csv('./data/raw/stats2.csv')\n",
    "matches_data = pd.read_csv('./data/raw/matches.csv')\n",
    "\n",
    "# Concatenate stat1 and stat2\n",
    "merged_stat_data = pd.concat([stat1_data, stat2_data])\n",
    "\n",
    "# Step 1: Merge participant_data with merged_stat_data on 'id'\n",
    "merged_data = pd.merge(participant_data, merged_stat_data, on='id', how='outer')\n",
    "\n",
    "# Step 2: Merge the resulting data with matches_data on 'matchid' and 'id'\n",
    "merged_data = pd.merge(merged_data, matches_data, left_on='matchid', right_on='id', how='inner')\n",
    "\n",
    "# Step 3: Remove the 'id_y' column and rename 'id_x' to 'participantid'\n",
    "merged_data = merged_data.drop(columns=['id_y']).rename(columns={'id_x': 'participantid'})\n",
    "\n",
    "# Step 4: Count the occurrences of each match_id in the merged_data\n",
    "match_id_counts = merged_data['matchid'].value_counts()\n",
    "\n",
    "# Step 5: Find match_ids that appear exactly 10 times\n",
    "match_ids_with_10_records = match_id_counts[match_id_counts == 10].index\n",
    "\n",
    "# Step 6: Filter merged_data to include only those records where the match_id appears 10 times\n",
    "participants_with_10_records = merged_data[merged_data['matchid'].isin(match_ids_with_10_records)]\n",
    "\n",
    "# Step 7: Define conditions for assigning roles\n",
    "conditions = [\n",
    "    (participants_with_10_records['role'] == 'SOLO') & (participants_with_10_records['position'] == 'TOP'),\n",
    "    (participants_with_10_records['role'] == 'NONE') & (participants_with_10_records['position'] == 'JUNGLE'),\n",
    "    (participants_with_10_records['role'] == 'SOLO') & (participants_with_10_records['position'] == 'MID'),\n",
    "    (participants_with_10_records['role'] == 'DUO_CARRY') & (participants_with_10_records['position'] == 'BOT'),\n",
    "    (participants_with_10_records['role'] == 'DUO_SUPPORT') & (participants_with_10_records['position'] == 'BOT')\n",
    "]\n",
    "\n",
    "# Define the corresponding values for each condition\n",
    "values = ['TOP', 'JUNGLE', 'MID', 'ADC', 'SUPPORT']\n",
    "\n",
    "# Create a new column 'role_position' and apply the conditions\n",
    "participants_with_10_records['role_position'] = np.select(conditions, values, default='UNKNOWN')\n",
    "\n",
    "# Step 8: Check each match_id to ensure both teams have exactly 5 unique roles\n",
    "valid_matches = []\n",
    "\n",
    "# Loop through each match_id\n",
    "for match_id in match_ids_with_10_records:\n",
    "    # Get the participants for this match\n",
    "    match_participants = participants_with_10_records[participants_with_10_records['matchid'] == match_id]\n",
    "    \n",
    "    # Split participants by their win/loss (1 = win, 0 = loss)\n",
    "    team1 = match_participants[match_participants['win'] == 1]\n",
    "    team2 = match_participants[match_participants['win'] == 0]\n",
    "    \n",
    "    # Ensure both teams have exactly 5 players and 5 unique roles\n",
    "    if len(team1) == 5 and len(team2) == 5:\n",
    "        if len(team1['role_position'].unique()) == 5 and len(team2['role_position'].unique()) == 5:\n",
    "            valid_matches.append(match_id)\n",
    "\n",
    "# Step 9: Filter the merged_data again to keep only valid matches\n",
    "valid_participants = participants_with_10_records[participants_with_10_records['matchid'].isin(valid_matches)]\n",
    "\n",
    "# Step 10: Save the result to a new CSV file\n",
    "# valid_participants.to_csv('../data/new/parti10records_unique_role.csv', index=False)\n",
    "\n",
    "print(f\"Number of valid matches with exactly 5 unique roles per team based on win/loss: {len(valid_matches)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter the columns to reduce the dataset size while retaining an overview of key metrics for each role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "data = pd.read_csv('../data/new/sample_participants_70percent.csv')\n",
    "\n",
    "# Specify the columns you want to keep\n",
    "columns_to_keep = [\n",
    "    'participantid', 'matchid', 'championid', 'win', 'kills', 'deaths', 'assists', 'largestkillingspree', 'largestmultikill', \n",
    "    'killingsprees', 'doublekills', 'triplekills', 'quadrakills', 'pentakills', 'legendarykills',\n",
    "    'totdmgdealt', 'totdmgtochamp', 'dmgtoobj', 'visionscore', 'totdmgtaken', 'goldearned', 'inhibkills', \n",
    "    'totminionskilled', 'neutralminionskilled', 'wardsbought', 'wardsplaced', 'wardskilled', 'role_position', 'duration'\n",
    "]\n",
    "\n",
    "# Filter the data\n",
    "filtered_data = data[columns_to_keep]\n",
    "\n",
    "# Save the filtered data to a new CSV file\n",
    "output_file_path = '../data/new/filtered_sample_participants_70percent.csv'\n",
    "filtered_data.to_csv(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate the dataset into subsets based on each role."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
