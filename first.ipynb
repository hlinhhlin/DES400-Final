{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is part of DES 400: Digital Engineering Project Development, offered by the Sirindhorn International Institute of Technology (SIIT), Thammasat University.\n",
    "\n",
    "Contributors:\n",
    "1. Atiluck Chanveeratham 6422771764\n",
    "2. Tanapat Suntornsirikul 6422781342\n",
    "3. Sirapat Eiamassavamongkol 6422781359\n",
    "4. Sorrawee Laowithayangkul 6422781565"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the raw data from https://www.kaggle.com/datasets/paololol/league-of-legends-ranked-matches/data?select=stats1.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section lists the core libraries and machine learning tools used in the notebook, along with their purposes:\n",
    "\n",
    "Core Libraries for Data Manipulation and Visualization\n",
    "- **pandas**: For data manipulation and analysis.\n",
    "- **numpy**: For numerical computing.\n",
    "- **seaborn**: For statistical data visualization.\n",
    "- **matplotlib.pyplot**: For creating static, interactive, and animated visualizations.\n",
    "- **itertools**: For efficient looping and handling combinatoric operations.\n",
    "\n",
    "Machine Learning Tools\n",
    "- **sklearn.ensemble.IsolationForest**: For anomaly detection using an ensemble-based isolation approach.\n",
    "- **sklearn.cluster.KMeans**: For clustering data points into groups based on their specified features.\n",
    "- **sklearn.preprocessing.StandardScaler**: For scaling data to standardize features.\n",
    "- **sklearn.metrics.silhouette_score**: For evaluating the quality of clusters using the silhouette coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries for data manipulation and visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "# Machine learning tools for clustering and anomaly detection\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section handles the loading, concatenation, and initial filtering of the dataset. Due to the large size of the data, it is split across two files, which are concatenated and then merged with participant and match data. Further filtering ensures the dataset is clean and adheres to specific constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Steps:**\n",
    "1. **Load the Data**:\n",
    "- `participants.csv`: Contains participant data, including information about players and roles.\n",
    "- `stats1.csv` and `stats2.csv`: Contain game statistics, divided into two files due to their size.\n",
    "- `matches.csv`: Contains match data, including match identifiers and related details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "participant_data = pd.read_csv('./data/participants.csv')\n",
    "stat1_data = pd.read_csv('./data/stats1.csv')\n",
    "stat2_data = pd.read_csv('./data/stats2.csv')\n",
    "matches_data = pd.read_csv('./data/matches.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Data Cleansing:**\n",
    "- `dmgtoobj`: Represents the total damage to objects, which inherently includes damage to turrets.\n",
    "- `dmgtoturrets`: Represents the specific damage to turrets.\n",
    "\n",
    "Assumption:\n",
    "\n",
    "Since turrets are a subset of objects, the value of `dmgtoturrets` cannot logically exceed `dmgtoobj`. Rows violating this rule indicate invalid data and are filtered out. Additionally, rows with missing or non-numeric values in these columns are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat1_data_cleaned = stat1_data[\n",
    "    pd.to_numeric(stat1_data['dmgtoobj'], errors='coerce') >= pd.to_numeric(stat1_data['dmgtoturrets'], errors='coerce')\n",
    "]\n",
    "stat1_data_cleaned = stat1_data_cleaned.dropna(subset=['dmgtoobj', 'dmgtoturrets'])\n",
    "\n",
    "stat2_data_cleaned = stat2_data[\n",
    "    pd.to_numeric(stat2_data['dmgtoobj'], errors='coerce') >= pd.to_numeric(stat2_data['dmgtoturrets'], errors='coerce')\n",
    "]\n",
    "stat2_data_cleaned = stat2_data_cleaned.dropna(subset=['dmgtoobj', 'dmgtoturrets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The shape of data before cleaning\n",
    "print(\"The shape of stat1_data before cleaning:\", stat1_data.shape)\n",
    "print(\"The shape of stat2_data before cleaning:\", stat2_data.shape)\n",
    "# The shape of data after cleaning\n",
    "print(\"The shape of stat1_data after cleaning:\", stat1_data_cleaned.shape)\n",
    "print(\"The shape of stat2_data after cleaning:\", stat2_data_cleaned.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Concatenate Large Datasets**:\n",
    "Combine `stats1.csv` and `stats2.csv` into a single dataset for unified processing.\n",
    "\n",
    "3. **Merge Datasets**:\n",
    "Merge the concatenated statistics with participant data and match data to create a comprehensive dataset.\n",
    "\n",
    "4. **Filter Matches**:\n",
    "- Retain only matches with exactly **10 participants**.\n",
    "- Ensure roles are unique and not duplicated within each team to maintain valid team compositions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Concatenate stat1 and stat2 data\n",
    "merged_stat_data = pd.concat([stat1_data_cleaned, stat2_data_cleaned], ignore_index=True)\n",
    "\n",
    "# Step 2: Merge participant_data with merged_stat_data on 'id'\n",
    "merged_data = pd.merge(participant_data, merged_stat_data, on='id', how='outer')\n",
    "\n",
    "# Step 3: Merge the resulting data with matches_data on 'matchid' and 'id'\n",
    "merged_data = pd.merge(merged_data, matches_data, left_on='matchid', right_on='id', how='inner')\n",
    "\n",
    "# Step 4: Clean up columns by removing 'id_y' and renaming 'id_x' to 'participantid'\n",
    "merged_data = (\n",
    "    merged_data\n",
    "    .drop(columns=['id_y'])\n",
    "    .rename(columns={'id_x': 'participantid'})\n",
    ")\n",
    "\n",
    "# Step 5: Count occurrences of each match_id\n",
    "match_id_counts = merged_data['matchid'].value_counts()\n",
    "\n",
    "# Step 6: Identify match_ids with exactly 10 occurrences\n",
    "match_ids_with_10_records = match_id_counts[match_id_counts == 10].index\n",
    "\n",
    "# Step 7: Filter merged_data for match_ids appearing 10 times\n",
    "participants_with_10_records = merged_data[\n",
    "    merged_data['matchid'].isin(match_ids_with_10_records)\n",
    "]\n",
    "\n",
    "# Step 8: Define conditions and corresponding values for assigning roles\n",
    "conditions = [\n",
    "    (participants_with_10_records['role'] == 'SOLO') & (participants_with_10_records['position'] == 'TOP'),\n",
    "    (participants_with_10_records['role'] == 'NONE') & (participants_with_10_records['position'] == 'JUNGLE'),\n",
    "    (participants_with_10_records['role'] == 'SOLO') & (participants_with_10_records['position'] == 'MID'),\n",
    "    (participants_with_10_records['role'] == 'DUO_CARRY') & (participants_with_10_records['position'] == 'BOT'),\n",
    "    (participants_with_10_records['role'] == 'DUO_SUPPORT') & (participants_with_10_records['position'] == 'BOT')\n",
    "]\n",
    "\n",
    "values = ['TOP', 'JUNGLE', 'MID', 'ADC', 'SUPPORT']\n",
    "\n",
    "# Step 9: Assign roles based on conditions and add a new column 'role_position'\n",
    "participants_with_10_records['role_position'] = np.select(conditions, values, default='UNKNOWN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10: Check each match_id to ensure both teams have exactly 5 unique roles\n",
    "# Group participants by matchid and win/loss, then check role uniqueness within teams\n",
    "valid_matches = participants_with_10_records.groupby(['matchid', 'win'])['role_position'].nunique()\n",
    "\n",
    "# Identify valid matches where both teams have exactly 5 unique roles\n",
    "valid_match_ids = valid_matches[valid_matches == 5].reset_index()\n",
    "\n",
    "# Further filter to get match_ids where both teams (win == 1 and win == 0) have exactly 5 roles\n",
    "valid_matches = valid_match_ids.groupby('matchid').filter(lambda x: len(x) == 2)['matchid'].unique()\n",
    "\n",
    "# Step 11: Filter the merged_data again to keep only valid matches\n",
    "valid_participants = participants_with_10_records[participants_with_10_records['matchid'].isin(valid_matches)]\n",
    "\n",
    "print(f\"Number of valid matches with exactly 5 unique roles per team based on win/loss: {len(valid_matches)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **Optimize DataFrame Size**:\n",
    "- Separate the dataset by roles (e.g., **Top, Jungle, Mid, ADC, Support**) to facilitate role-specific analysis.\n",
    "- Select only relevant columns to reduce the size of the DataFrame, focusing on key features needed for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the columns you want to keep\n",
    "columns_to_keep = [\n",
    "    'participantid', 'matchid', 'championid', 'win', 'kills', 'deaths', 'assists', 'largestkillingspree', 'largestmultikill', \n",
    "    'killingsprees', 'totdmgdealt', 'totdmgtochamp', 'dmgtoobj', 'dmgtoturrets', 'visionscore', 'totdmgtaken', 'goldearned', 'inhibkills', \n",
    "    'totminionskilled', 'neutralminionskilled', 'wardsbought', 'wardsplaced', 'wardskilled', 'role_position', 'duration'\n",
    "]\n",
    "\n",
    "# First filtering based on domain knowledge\n",
    "filtered_data = valid_participants[columns_to_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we adjust the `deaths` column to better align with performance metrics. Since a higher number of deaths indicates poorer performance, the values in this column are made negative to reflect this relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to make the 'deaths' column negative\n",
    "def make_column_negative(df, column_name='deaths'):\n",
    "    if column_name in df.columns:\n",
    "        df[column_name] = -df[column_name]\n",
    "    return df\n",
    "\n",
    "# Apply the function to the entire DataFrame first\n",
    "filtered_data = make_column_negative(filtered_data)\n",
    "\n",
    "# Then filter by role position\n",
    "top_laners_df = filtered_data[filtered_data['role_position'] == 'TOP']\n",
    "junglers_df = filtered_data[filtered_data['role_position'] == 'JUNGLE']\n",
    "mid_laners_df = filtered_data[filtered_data['role_position'] == 'MID']\n",
    "adc_df = filtered_data[filtered_data['role_position'] == 'ADC']\n",
    "supports_df = filtered_data[filtered_data['role_position'] == 'SUPPORT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. **Feature Engineering and Scaling**:\n",
    "Divide time-dependent features (e.g., damage, gold, kills) by **match duration** to standardize values across matches of varying lengths and etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_by_duration(df, metrics, suffix='_per_minute'):\n",
    "    # Ensure 'duration' column exists and convert to minutes (if in seconds)\n",
    "    if 'duration' not in df.columns:\n",
    "        raise ValueError(\"'duration' column is missing from the DataFrame.\")\n",
    "    df['duration'] = df['duration'] / 60\n",
    "    \n",
    "    for metric in metrics:\n",
    "        # Ensure metric exists in the DataFrame\n",
    "        if metric not in df.columns:\n",
    "            raise ValueError(f\"'{metric}' column is missing from the DataFrame.\")\n",
    "        \n",
    "        # Create a new column with the suffix to store the divided value\n",
    "        new_column_name = metric + suffix\n",
    "        \n",
    "        # Check for zero duration to avoid division by zero errors\n",
    "        if df['duration'].min() == 0:\n",
    "            raise ValueError(\"Some rows have a duration of zero, cannot divide by zero.\")\n",
    "        \n",
    "        # Perform the division\n",
    "        df[new_column_name] = df[metric] / df['duration']\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Generate dmg_per_kill (safe division)\n",
    "def generate_dmg_per_kill(df, dmg_col='totdmgtochamp', kills_col='kills', new_feature_name='dmg_per_kill'):\n",
    "    df[new_feature_name] = df[dmg_col] / df[kills_col]\n",
    "    return df\n",
    "\n",
    "# Generate visionscore_per_wardplaced (safe division)\n",
    "def generate_visionscore_per_wardplaced(df, visionscore_col='visionscore', wardsplaced_col='wardsplaced', new_feature_name='visionscore_per_wardplaced'):\n",
    "    if visionscore_col in df.columns and wardsplaced_col in df.columns:\n",
    "        df[new_feature_name] = df.apply(lambda x: x[visionscore_col] / x[wardsplaced_col] if x[wardsplaced_col] != 0 else 0, axis=1)\n",
    "    else:\n",
    "        raise ValueError(f\"Columns '{visionscore_col}' and/or '{wardsplaced_col}' are missing from the DataFrame.\")\n",
    "    return df\n",
    "\n",
    "# Fill 'wardsbought' with the average, handling non-numeric entries\n",
    "def fill_wardsbought_with_average(df):\n",
    "    if 'wardsbought' not in df.columns:\n",
    "        raise ValueError(\"'wardsbought' column is missing from the DataFrame.\")\n",
    "    \n",
    "    # Convert non-numeric entries to NaN\n",
    "    df['wardsbought'] = pd.to_numeric(df['wardsbought'], errors='coerce')\n",
    "    \n",
    "    # Calculate and fill NaN values with the average\n",
    "    average_wardsbought = df['wardsbought'].mean()  # Automatically ignores NaN values\n",
    "    df['wardsbought'].fillna(average_wardsbought, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADC Role\n",
    "adc_metrics_to_divide = ['totdmgtochamp', 'totminionskilled', 'dmgtoobj', 'goldearned', 'kills', 'deaths', 'assists', 'dmgtoturrets']\n",
    "adc_divided = divide_by_duration(adc_df, adc_metrics_to_divide)\n",
    "\n",
    "# Support Role\n",
    "supports_df = fill_wardsbought_with_average(supports_df)\n",
    "support_metrics_to_divide = ['visionscore', 'wardsplaced', 'wardskilled', 'wardsbought', 'totdmgtaken', 'kills', 'deaths', 'assists']\n",
    "support_divided = divide_by_duration(supports_df, support_metrics_to_divide)\n",
    "\n",
    "# Mid Role\n",
    "mid_metrics_to_divide = ['totdmgtochamp', 'goldearned','visionscore', 'dmgtoobj', 'totdmgdealt','totminionskilled', 'kills', 'deaths', 'assists']\n",
    "mid_divided = divide_by_duration(mid_laners_df, mid_metrics_to_divide)\n",
    "\n",
    "# Top Role\n",
    "top_metrics_to_divide = ['totdmgtaken', 'deaths', 'assists', 'goldearned', 'totdmgtochamp', 'totminionskilled', 'totdmgdealt', 'kills']\n",
    "top_damage_per_kill = generate_dmg_per_kill(top_laners_df)\n",
    "top_divided = divide_by_duration(top_damage_per_kill, top_metrics_to_divide)\n",
    "\n",
    "# Jungle Role\n",
    "jungle_metrics_to_divide = ['neutralminionskilled', 'kills', 'assists', 'goldearned','visionscore', 'totdmgdealt', 'dmgtoobj', 'totdmgtochamp', 'deaths', 'dmgtoturrets', 'inhibkills']\n",
    "jungle_divided = divide_by_duration(junglers_df, jungle_metrics_to_divide)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Correlation Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function generates and visualizes a correlation matrix for selected features in the dataset. It helps identify relationships between variables for a specific role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_correlation_matrix(df, features, role_name):\n",
    "    metrics = df[features]\n",
    "\n",
    "    # Check for columns with string values and report them\n",
    "    non_numeric_columns = metrics.select_dtypes(include=['object']).columns\n",
    "    if not non_numeric_columns.empty:\n",
    "        print(f\"Warning: The following columns in {role_name} contain non-numeric data:\")\n",
    "        print(non_numeric_columns)\n",
    "        for col in non_numeric_columns:\n",
    "            print(f\"Non-numeric values in '{col}':\")\n",
    "            print(metrics[col].unique())\n",
    "\n",
    "    # Convert all columns to numeric, forcing errors to NaN\n",
    "    metrics = metrics.apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    # Drop rows with NaN values\n",
    "    metrics = metrics.dropna()\n",
    "\n",
    "    # Calculate correlation matrix\n",
    "    correlation_matrix = metrics.corr()\n",
    "\n",
    "    # Visualize the correlation matrix using a heatmap\n",
    "    plt.figure(figsize=(12, 10))  # Increase figure size to give more space for labels\n",
    "    heatmap = sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "    \n",
    "    # Set the title of the heatmap\n",
    "    plt.title(f'Correlation Matrix for {role_name} Features')\n",
    "    \n",
    "    # Adjust layout to avoid cutting off labels\n",
    "    plt.subplots_adjust(left=0.25, right=0.9, top=0.9, bottom=0.25)  # Adjust both left and bottom margins\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To analyze feature relationships for different roles in the dataset, correlation matrices are generated and visualized for key metrics specific to each role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_before_correlation = {\n",
    "    \"adc\": [\n",
    "        'totdmgtochamp_per_minute', 'totminionskilled_per_minute', 'goldearned_per_minute', 'largestkillingspree', \n",
    "        'largestmultikill', 'dmgtoobj_per_minute', 'kills_per_minute', 'deaths_per_minute', 'assists_per_minute', 'dmgtoturrets_per_minute'\n",
    "        ],\n",
    "    \"support\": [\n",
    "        'wardskilled_per_minute', 'wardsplaced_per_minute', 'visionscore_per_minute', 'wardsbought_per_minute', \n",
    "        'totdmgtaken_per_minute', 'kills_per_minute', 'deaths_per_minute', 'assists_per_minute'\n",
    "        ],\n",
    "    \"mid\": [\n",
    "        'totdmgtochamp_per_minute', 'goldearned_per_minute', 'largestkillingspree', 'visionscore_per_minute', 'totdmgdealt_per_minute', \n",
    "        'dmgtoobj_per_minute', 'totminionskilled_per_minute', 'kills_per_minute', 'deaths_per_minute', 'assists_per_minute'\n",
    "        ],\n",
    "    \"top\": [\n",
    "         'totdmgtaken_per_minute', 'deaths_per_minute', 'dmg_per_kill', 'goldearned_per_minute', 'totdmgtochamp_per_minute', \n",
    "        'assists_per_minute', 'totdmgdealt_per_minute', 'kills_per_minute', 'largestkillingspree', 'totminionskilled_per_minute',\n",
    "        ],\n",
    "    \"jungle\": [\n",
    "        'neutralminionskilled_per_minute', 'kills_per_minute', 'assists_per_minute', 'killingsprees',\n",
    "        'visionscore_per_minute', 'totdmgdealt_per_minute', 'dmgtoobj_per_minute', 'totdmgtochamp_per_minute', 'deaths_per_minute', \n",
    "        'goldearned_per_minute', 'dmgtoturrets_per_minute', 'inhibkills_per_minute', 'largestmultikill'\n",
    "        ]\n",
    "}\n",
    "\n",
    "visualize_correlation_matrix(adc_divided, metrics_before_correlation['adc'], 'ADC')\n",
    "visualize_correlation_matrix(support_divided, metrics_before_correlation['support'], 'Support')\n",
    "visualize_correlation_matrix(mid_divided, metrics_before_correlation['mid'], 'Mid')\n",
    "visualize_correlation_matrix(top_divided, metrics_before_correlation['top'], 'Top')\n",
    "visualize_correlation_matrix(jungle_divided, metrics_before_correlation['jungle'], 'Jungle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the feature pairs having high correlation and plot the heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_columns(metrics_before_correlation, columns_to_exclude):\n",
    "    metrics_after_correlation = {}\n",
    "    \n",
    "    for role, metrics in metrics_before_correlation.items():\n",
    "        # Exclude columns specified in columns_to_exclude for the given role\n",
    "        excluded_columns = columns_to_exclude.get(role, [])\n",
    "        filtered_metrics = [metric for metric in metrics if metric not in excluded_columns]\n",
    "        \n",
    "        # Update the result with the filtered metrics for each role\n",
    "        metrics_after_correlation[role] = filtered_metrics\n",
    "    \n",
    "    return metrics_after_correlation\n",
    "\n",
    "columns_to_exclude = {\n",
    "    \"adc\": ['goldearned_per_minute', 'kills_per_minute'],\n",
    "    \"support\": [],\n",
    "    \"mid\": ['goldearned_per_minute', 'largestkillingspree'],\n",
    "    \"top\": ['largestkillingspree', 'goldearned_per_minute'],\n",
    "    \"jungle\": ['killingsprees']\n",
    "}\n",
    "\n",
    "# Calling the function to get the filtered metrics\n",
    "metrics_after_correlation = remove_columns(metrics_before_correlation, columns_to_exclude)\n",
    "\n",
    "# Output the result\n",
    "print(metrics_after_correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_correlation_matrix(adc_divided, metrics_after_correlation['adc'], 'ADC')\n",
    "visualize_correlation_matrix(support_divided, metrics_after_correlation['support'], 'Support')\n",
    "visualize_correlation_matrix(mid_divided, metrics_after_correlation['mid'], 'Mid')\n",
    "visualize_correlation_matrix(top_divided, metrics_after_correlation['top'], 'Top')\n",
    "visualize_correlation_matrix(jungle_divided, metrics_after_correlation['jungle'], 'Jungle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elbow Method, Silhouette Analysis, and Anomaly Detection with Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the color for plotting KMeans clusters\n",
    "\n",
    "color_for_plot = {\n",
    "    0: 'orange',\n",
    "    1: 'red',\n",
    "    2: 'blue',\n",
    "    3: 'green',\n",
    "    4: 'purple',\n",
    "    5: 'brown',\n",
    "    6: 'pink',\n",
    "    7: 'gray',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function performs **Elbow** and **Silhouette** analyses to determine the optimal number of clusters for a given role. It helps identify the best clustering configuration by evaluating inertia and silhouette scores across different cluster numbers.\n",
    "\n",
    "Process:\n",
    "1. **Elbow Plot**:\n",
    "- Plots the inertia values (within-cluster sum of squares) for cluster sizes ranging from 2 to 10.\n",
    "- The \"elbow\" in the plot indicates the optimal number of clusters where the inertia starts to decrease at a slower rate.\n",
    "\n",
    "2. **Silhouette Plot**:\n",
    "- Measures how similar data points are within a cluster compared to other clusters.\n",
    "- Higher silhouette scores suggest better-defined clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_elbow_silhouette(df, features, role):\n",
    "    \"\"\"\n",
    "    Plots elbow and silhouette methods to determine optimal clusters for a role.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The data frame containing the features.\n",
    "        features (list): List of feature names to be used for clustering.\n",
    "        role (str): The role for which the analysis is being performed.\n",
    "    \"\"\"\n",
    "    max_clusters = 10\n",
    "    inertia_values, silhouette_values = [], []\n",
    "    # generates a sequence of integers from 2 to max_clusters (inclusive) (cluster 2 to 10)\n",
    "    cluster_range = range(2, max_clusters + 1)\n",
    "\n",
    "    for k in cluster_range:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        labels = kmeans.fit_predict(df[features])\n",
    "        inertia_values.append(kmeans.inertia_)\n",
    "        silhouette_values.append(silhouette_score(df[features], labels))\n",
    "\n",
    "    # Elbow plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(cluster_range, inertia_values, 'bo-')\n",
    "    plt.title(f'{role.capitalize()} Elbow Plot')\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('Inertia (within cluster sum of squares)')\n",
    "\n",
    "    # Silhouette plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(cluster_range, silhouette_values, 'go-')\n",
    "    plt.title(f'{role.capitalize()} Silhouette Score Plot')\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('Silhouette Score')\n",
    "\n",
    "    plt.suptitle(f'Elbow and Silhouette Analysis for {role.capitalize()} Role')\n",
    "    plt.show()\n",
    "    # plt.savefig(f\"./Isolation-forest-getInsight/Elbow-silhouette/{role}_elbow_silhouette_plot.png\", dpi=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function performs anomaly detection using the **Isolation Forest** algorithm, identifies normal vs. anomaly data points, and visualizes the results. The analysis is combined with **Elbow** and **Silhouette** methods for clustering insights.\n",
    "\n",
    "Process:\n",
    "1. **Data Preprocessing**:\n",
    "- Drops unnecessary columns and handles missing, infinite, or outlier values.\n",
    "- Scales the data using **StandardScaler** for consistent metric comparison.\n",
    "   \n",
    "2. **Isolation Forest**:\n",
    "- Detects anomalies in the data by isolating them based on feature distributions.\n",
    "- Anomalies are marked with `-1`, and normal data is labeled as `1`.\n",
    "\n",
    "3. **Visualization**:\n",
    "- **Elbow and Silhouette Plots** for anomaly data to determine optimal clusters.\n",
    "- **Normal vs Anomaly Plot** visualizes how the normal and anomaly data points distribute across different feature combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isolation_forest_plot_elbow_silhouette(role, data_role):\n",
    "    print(f\"Processing role: {role}\")\n",
    "    \n",
    "    df = data_role.drop(columns=['role_position'], errors='ignore')\n",
    "    \n",
    "    # Select features and preprocess\n",
    "    features = metrics_after_correlation[role]\n",
    "    X = df[features].apply(pd.to_numeric, errors='coerce').dropna()\n",
    "    X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    X = np.clip(X, a_min=-1e5, a_max=1e5).dropna()\n",
    "    df = df.loc[X.index]\n",
    "\n",
    "    # Scale data\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Isolation Forest\n",
    "    iso_forest = IsolationForest(contamination=0.01, random_state=42)\n",
    "    df['anomaly'] = iso_forest.fit_predict(X_scaled)\n",
    "\n",
    "    anomaly_data = df[df['anomaly'] == -1]\n",
    "    normal_data = df[df['anomaly'] != -1]\n",
    "\n",
    "    # Plot elbow and silhouette for anomaly data\n",
    "    plot_elbow_silhouette(anomaly_data, features, role)\n",
    "\n",
    "    # Plot normal vs anomaly data\n",
    "    plot_normal_vs_anomaly(normal_data, anomaly_data, features, role)\n",
    "\n",
    "    return anomaly_data, normal_data\n",
    "\n",
    "\n",
    "def plot_normal_vs_anomaly(normal_data, anomaly_data, features, role):\n",
    "    \"\"\"\n",
    "    Plots normal (blue) and anomaly (red) data points for all feature combinations.\n",
    "\n",
    "    Args:\n",
    "        normal_data (DataFrame): Data classified as normal.\n",
    "        anomaly_data (DataFrame): Data classified as anomalies.\n",
    "        features (list): List of feature columns.\n",
    "        role (str): Role name for the plot title.\n",
    "        alpha_normal (float): Transparency level for normal data points (default: 0.4).\n",
    "        alpha_anomaly (float): Transparency level for anomaly data points (default: 0.6).\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate feature combinations for scatter plots\n",
    "    feature_combinations = list(itertools.combinations(features, 2))\n",
    "    n_cols = 4\n",
    "    n_rows = (len(feature_combinations) + n_cols - 1) // n_cols\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(18, n_rows * 3))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, (feature_x, feature_y) in enumerate(feature_combinations):\n",
    "        ax = axes[i]\n",
    "\n",
    "        # Plot normal data points (blue, customizable alpha)\n",
    "        ax.scatter(\n",
    "            normal_data[feature_x], \n",
    "            normal_data[feature_y], \n",
    "            c='blue', \n",
    "            label='Normal', \n",
    "            alpha=0.2\n",
    "        )\n",
    "\n",
    "        # Plot anomaly data points (red, customizable alpha)\n",
    "        ax.scatter(\n",
    "            anomaly_data[feature_x], \n",
    "            anomaly_data[feature_y], \n",
    "            c='red', \n",
    "            label='Anomaly', \n",
    "            alpha=0.2\n",
    "        )\n",
    "\n",
    "        # Add labels and title\n",
    "        ax.set_title(f'{feature_x} vs {feature_y}', fontsize=8)\n",
    "        ax.set_xlabel(feature_x, fontsize=8)\n",
    "        ax.set_ylabel(feature_y, fontsize=8)\n",
    "\n",
    "    # Remove extra subplots if any\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    fig.suptitle(f'Normal vs Anomaly Plot for {role.capitalize()} Role', fontsize=16)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(adc_anomaly, adc_normal) = isolation_forest_plot_elbow_silhouette('adc', adc_divided)\n",
    "(support_anomaly, support_normal) = isolation_forest_plot_elbow_silhouette('support', support_divided)\n",
    "(mid_anomaly, mid_normal) = isolation_forest_plot_elbow_silhouette('mid', mid_divided)    \n",
    "(top_anomaly, top_normal) = isolation_forest_plot_elbow_silhouette('top', top_divided)\n",
    "(jungle_anomaly, jungle_normal) = isolation_forest_plot_elbow_silhouette('jungle', jungle_divided)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means Clustering for Outlier Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section utilizes **K-Means clustering** to analyze and visualize outliers within the dataset based on selected features. The results are shown in multiple ways:\n",
    "1. Cluster analysis across feature combinations.\n",
    "2. Detailed visualizations of individual clusters.\n",
    "\n",
    "Key Functions:\n",
    "1. **`compute_axis_limits`**:\n",
    "- Computes the axis limits for scatter plots based on feature combinations to ensure consistent visualization across all plots.\n",
    "\n",
    "2. **`analyze_outliers_with_kmeans`**:\n",
    "- Applies **K-Means clustering** on the scaled data.\n",
    "- Adds a `kmeans_cluster` column to the DataFrame for cluster assignments.\n",
    "- Plots the overall cluster distribution and individual clusters for better insight.\n",
    "\n",
    "3. **`plot_clusters`**:\n",
    "- Plots all the clusters in 2D scatter plots for each feature pair.\n",
    "- Ensures consistent axis limits across plots for clarity.\n",
    "\n",
    "4. **`plot_each_cluster`**:\n",
    "- Visualizes each cluster individually, making it easier to analyze data points within specific clusters.\n",
    "- Provides a detailed view of the data points belonging to a particular cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to compute axis limits\n",
    "def compute_axis_limits(df, features):\n",
    "    feature_combinations = list(itertools.combinations(features, 2))\n",
    "    axis_limits = {}\n",
    "    for feature_x, feature_y in feature_combinations:\n",
    "        x_min, x_max = df[feature_x].min(), df[feature_x].max()\n",
    "        y_min, y_max = df[feature_y].min(), df[feature_y].max()\n",
    "        axis_limits[(feature_x, feature_y)] = (x_min, x_max, y_min, y_max)\n",
    "    return axis_limits\n",
    "\n",
    "# Function to analyze outliers with KMeans\n",
    "def analyze_outliers_with_kmeans(outliers_df, features, role, n_clusters):\n",
    "    scaler = StandardScaler()\n",
    "    X_outliers_scaled = scaler.fit_transform(outliers_df[features])\n",
    "\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    outliers_df['kmeans_cluster'] = kmeans.fit_predict(X_outliers_scaled)\n",
    "    \n",
    "    axis_limits = compute_axis_limits(outliers_df, features)\n",
    "    \n",
    "    plot_clusters(outliers_df, features, f\"{role.capitalize()} KMeans Cluster Analysis with {n_clusters} Clusters\", axis_limits)\n",
    "\n",
    "    for cluster in outliers_df['kmeans_cluster'].unique():\n",
    "        plot_each_cluster(outliers_df, features, cluster, f\"{role.capitalize()} KMeans Cluster Analysis with {n_clusters} Clusters\", axis_limits)\n",
    "        \n",
    "    return outliers_df\n",
    "\n",
    "# Function to plot all clusters\n",
    "def plot_clusters(df, features, title, axis_limits):\n",
    "    feature_combinations = list(itertools.combinations(features, 2))\n",
    "    n_cols = 4\n",
    "    n_rows = (len(feature_combinations) + n_cols - 1) // n_cols\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(18, n_rows * 3))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, (feature_x, feature_y) in enumerate(feature_combinations):\n",
    "        ax = axes[i]\n",
    "        for cluster in df['kmeans_cluster'].unique():\n",
    "            cluster_data = df[df['kmeans_cluster'] == cluster]\n",
    "            cluster_color = color_for_plot.get(cluster, 'gray')  # Default to 'gray' if cluster color is not defined\n",
    "            ax.scatter(cluster_data[feature_x], cluster_data[feature_y], label=f'Cluster {cluster}', color=cluster_color, alpha=0.3)\n",
    "        ax.set_title(f'{feature_x} vs {feature_y}', fontsize=8)\n",
    "        ax.set_xlabel(feature_x, fontsize=8)\n",
    "        ax.set_ylabel(feature_y, fontsize=8)\n",
    "\n",
    "        # Apply axis limits\n",
    "        x_min, x_max, y_min, y_max = axis_limits[(feature_x, feature_y)]\n",
    "        ax.set_xlim(x_min, x_max)\n",
    "        ax.set_ylim(y_min, y_max)\n",
    "\n",
    "    # Remove unused subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Function to plot each cluster\n",
    "def plot_each_cluster(df, features, cluster, title, axis_limits):\n",
    "    cluster_data = df[df['kmeans_cluster'] == cluster]\n",
    "    print(f\"Cluster {cluster}: {len(cluster_data)} data points\")\n",
    "    feature_combinations = list(itertools.combinations(features, 2))\n",
    "    n_cols = 4\n",
    "    n_rows = (len(feature_combinations) + n_cols - 1) // n_cols\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(18, n_rows * 3))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, (feature_x, feature_y) in enumerate(feature_combinations):\n",
    "        ax = axes[i]\n",
    "        cluster_color = color_for_plot.get(cluster, 'gray')  # Default to 'gray' if cluster color is not defined\n",
    "        ax.scatter(cluster_data[feature_x], cluster_data[feature_y], color=cluster_color, alpha=0.3)\n",
    "        ax.set_title(f'{feature_x} vs {feature_y}', fontsize=8)\n",
    "        ax.set_xlabel(feature_x, fontsize=8)\n",
    "        ax.set_ylabel(feature_y, fontsize=8)\n",
    "\n",
    "        # Apply axis limits\n",
    "        x_min, x_max, y_min, y_max = axis_limits[(feature_x, feature_y)]\n",
    "        ax.set_xlim(x_min, x_max)\n",
    "        ax.set_ylim(y_min, y_max)\n",
    "\n",
    "    # Remove unused subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "    \n",
    "    fig.suptitle(f'{title} - Cluster {cluster}', fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the number of clusters for each role based on our conclusions\n",
    "adc_cluster_counts = 7\n",
    "support_cluster_counts = 4\n",
    "mid_cluster_counts = 4\n",
    "top_cluster_counts = 5\n",
    "jungle_cluster_counts = 6\n",
    "\n",
    "adc_outlier_kmean = analyze_outliers_with_kmeans(adc_anomaly, metrics_after_correlation['adc'], 'adc', adc_cluster_counts)\n",
    "support_outlier_kmean = analyze_outliers_with_kmeans(support_anomaly, metrics_after_correlation['support'], 'support', support_cluster_counts)\n",
    "mid_outlier_kmean = analyze_outliers_with_kmeans(mid_anomaly, metrics_after_correlation['mid'], 'mid', mid_cluster_counts)\n",
    "top_outlier_kmean = analyze_outliers_with_kmeans(top_anomaly, metrics_after_correlation['top'], 'top', top_cluster_counts)\n",
    "jungle_outlier_kmean = analyze_outliers_with_kmeans(jungle_anomaly, metrics_after_correlation['jungle'], 'jungle', jungle_cluster_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z-score Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `normalize_features` is designed to normalize selected features in a dataset to the range [0, 1]. This ensures that all features are scaled uniformly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_features(df, feature_cols):\n",
    "    \"\"\"\n",
    "    Normalize features to the range [0, 1].\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The input dataframe.\n",
    "        feature_cols (list): List of columns to normalize.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A dataframe with normalized features.\n",
    "    \"\"\"\n",
    "    df_normalized = df.copy()\n",
    "    for col in feature_cols:\n",
    "        min_val = df[col].min()\n",
    "        max_val = df[col].max()\n",
    "        df_normalized[col] = (df[col] - min_val) / (max_val - min_val)\n",
    "    return df_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `zscore_plot_normalized` function generates a scatter plot showing the normalized scores of features in a dataset, segmented by clusters. It also identifies and annotates outliers based on z-score thresholds. This function is useful for visualizing data distributions and detecting anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zscore_plot_normalized(df, cluster_col, feature_cols, role, all_df):\n",
    "    thresholds = [2, 2.5, 3, 3.5]\n",
    "\n",
    "    all_df_normalized = normalize_features(all_df, feature_cols)\n",
    "    all_df_normalized['normalized_score_combined'] = all_df_normalized[feature_cols].sum(axis=1)\n",
    "    all_df = all_df.reset_index(drop=True)\n",
    "    all_df_normalized = all_df_normalized.reset_index(drop=True)\n",
    "\n",
    "    # Normalize the selected features\n",
    "    df_normalized = normalize_features(df, feature_cols)\n",
    "\n",
    "    # Combine normalized scores by summing across features\n",
    "    df_normalized['normalized_score_combined'] = df_normalized[feature_cols].sum(axis=1)\n",
    "\n",
    "    # Ensure the index is a range index for consistent plotting\n",
    "    df = df.reset_index(drop=True)\n",
    "    df_normalized = df_normalized.reset_index(drop=True)\n",
    "\n",
    "    # Scatter plot by cluster\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    unique_clusters = df[cluster_col].unique()\n",
    "\n",
    "    for cluster in unique_clusters:\n",
    "        cluster_data = df[df[cluster_col] == cluster]\n",
    "        color = color_for_plot.get(cluster, 'gray')  # Default to gray if cluster color is not defined\n",
    "        plt.scatter(\n",
    "            cluster_data.index,\n",
    "            df_normalized.loc[cluster_data.index, 'normalized_score_combined'],\n",
    "            label=f'Cluster {cluster}',\n",
    "            color=color,\n",
    "            alpha=0.5\n",
    "        )\n",
    "\n",
    "    # Process thresholds if provided\n",
    "    outliers_count = {}\n",
    "    if thresholds:\n",
    "        for idx, threshold in enumerate(thresholds):\n",
    "            threshold_value = all_df_normalized['normalized_score_combined'].mean() + threshold * all_df_normalized['normalized_score_combined'].std()\n",
    "            \n",
    "            # Identify outliers\n",
    "            outliers = all_df_normalized[all_df_normalized['normalized_score_combined'] > threshold_value]\n",
    "            outliers_count[threshold] = len(outliers)\n",
    "\n",
    "            # Plot the threshold line\n",
    "            plt.axhline(threshold_value, color='red', linestyle='dashed', linewidth=1, label=f'Threshold {threshold}')\n",
    "            vertical_offset = 0.9 - idx * 0.1  # Adjust vertical position for each threshold\n",
    "            plt.text(df.index[-1] * 0.95, threshold_value, f'Threshold {threshold}', color='red', rotation=0, ha='right')\n",
    "\n",
    "        # Annotate the number of outliers for each threshold\n",
    "        annotation_text = \"\\n\".join([f\"Threshold {threshold}: {count} outliers\" for threshold, count in outliers_count.items()])\n",
    "        plt.text(len(df) * 0.95, max(df_normalized['normalized_score_combined']) * 0.8, annotation_text, fontsize=10,\n",
    "                 bbox=dict(facecolor='white', alpha=0.7), ha='right', va='top')\n",
    "\n",
    "        # Print outliers for each threshold\n",
    "        for threshold, count in outliers_count.items():\n",
    "            print(f\"Outliers at threshold {threshold}: {count} outliers\")\n",
    "            print(f\"It is about {count / len(df) * 100:.2f}% of the total data\")\n",
    "    else:\n",
    "        print(\"No thresholds provided, skipping outlier calculation.\")\n",
    "    \n",
    "    plt.title(f'Normalized Metrics Plot by Cluster {role.capitalize()}')\n",
    "    plt.xlabel('Record Index')\n",
    "    plt.ylabel('Normalized Combined Score')\n",
    "    plt.legend()\n",
    "\n",
    "    # Uncomment to save the plot\n",
    "    # plt.savefig(f\"action/initial-plot/cross-validation/plot/{role}_normalized_zscore.png\", dpi=100)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zscore_plot_normalized(adc_outlier_kmean, 'kmeans_cluster', metrics_after_correlation['adc'], 'ADC', adc_divided)\n",
    "zscore_plot_normalized(support_outlier_kmean, 'kmeans_cluster', metrics_after_correlation['support'], 'Support', support_divided)\n",
    "zscore_plot_normalized(mid_outlier_kmean, 'kmeans_cluster', metrics_after_correlation['mid'], 'Mid', mid_divided)\n",
    "zscore_plot_normalized(top_outlier_kmean, 'kmeans_cluster', metrics_after_correlation['top'], 'Top', top_divided)\n",
    "zscore_plot_normalized(jungle_outlier_kmean, 'kmeans_cluster', metrics_after_correlation['jungle'], 'Jungle', jungle_divided)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `process_role_data` function calculates and visualizes the performance distribution of data based on normalized feature scores for different roles. It also detects and annotates outliers based on predefined z-score thresholds. This function helps in identifying performance patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_role_data(all_df, df, feature_cols, thresholds=None):\n",
    "    all_df_normalized = normalize_features(all_df, feature_cols)\n",
    "    all_df_normalized['normalized_score_combined'] = all_df_normalized[feature_cols].sum(axis=1)\n",
    "    all_df = all_df.reset_index(drop=True)\n",
    "    all_df_normalized = all_df_normalized.reset_index(drop=True)\n",
    "    \n",
    "    df_normalized = normalize_features(df, feature_cols)\n",
    "    # Combine normalized scores by summing across features\n",
    "    df_normalized['normalized_score_combined'] = df_normalized[feature_cols].sum(axis=1)\n",
    "\n",
    "    # Drop rows with NaN values\n",
    "    df_normalized = df_normalized.dropna(subset=feature_cols)\n",
    "\n",
    "    overall_performance = df_normalized['normalized_score_combined']\n",
    "    \n",
    "    # Create histogram\n",
    "    bins = np.linspace(overall_performance.min(), overall_performance.max(), 50)\n",
    "    counts, edges = np.histogram(overall_performance, bins=bins)\n",
    "\n",
    "    # Plot the histogram\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(edges[:-1], counts, width=np.diff(edges), color='skyblue', edgecolor='black')\n",
    "\n",
    "    # Process thresholds if provided\n",
    "    outliers_count = {}\n",
    "    if thresholds:\n",
    "        for idx, threshold in enumerate(thresholds):\n",
    "            threshold_value = all_df_normalized['normalized_score_combined'].mean() + threshold * all_df_normalized['normalized_score_combined'].std()\n",
    "            \n",
    "            # Identify outliers\n",
    "            outliers = all_df_normalized[all_df_normalized['normalized_score_combined'] > threshold_value]\n",
    "            outliers_count[threshold] = len(outliers)\n",
    "\n",
    "            # Plot the threshold line\n",
    "            plt.axvline(threshold_value, color='red', linestyle='dashed', linewidth=1, label=f'Threshold {threshold}')\n",
    "            vertical_offset = 0.9 - idx * 0.1  # Adjust vertical position for each threshold\n",
    "            plt.text(threshold_value, max(counts) * vertical_offset, f'Threshold {threshold}', color='red', rotation=45, ha='right')\n",
    "\n",
    "        # Annotate the number of outliers for each threshold\n",
    "        annotation_text = \"\\n\".join([f\"Threshold {threshold}: {count} outliers\" for threshold, count in outliers_count.items()])\n",
    "        plt.text(overall_performance.max() * 0.95, max(counts) * 0.8, annotation_text, fontsize=10,\n",
    "                 bbox=dict(facecolor='white', alpha=0.7), ha='right', va='top')\n",
    "\n",
    "        # Print outliers for each threshold\n",
    "        for threshold, count in outliers_count.items():\n",
    "            print(f\"Outliers at threshold {threshold}: {count} outliers\")\n",
    "            print(f\"It is about {count / len(df) * 100:.2f}% of the total data\")\n",
    "    else:\n",
    "        print(\"No thresholds provided, skipping outlier calculation.\")\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel('Overall Performance Score')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Performance Distribution {(\"(Thresholds: \" + str(thresholds) + \")\") if thresholds else \"\"}')\n",
    "    plt.legend(loc='upper right' if thresholds else None)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return overall_performance\n",
    "\n",
    "\n",
    "# Define thresholds for detecting outliers\n",
    "thresholds = [2, 2.5, 3, 3.5]\n",
    "\n",
    "process_role_data(adc_divided, adc_divided, metrics_after_correlation['adc'], thresholds)\n",
    "process_role_data(support_divided, support_divided, metrics_after_correlation['support'], thresholds)\n",
    "process_role_data(mid_divided, mid_divided, metrics_after_correlation['mid'], thresholds)\n",
    "process_role_data(top_divided, top_divided, metrics_after_correlation['top'], thresholds)\n",
    "process_role_data(jungle_divided, jungle_divided, metrics_after_correlation['jungle'], thresholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the z-score distribution for anomaly data detected by isolation forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_role_data(adc_divided, adc_outlier_kmean, metrics_after_correlation['adc'], thresholds)\n",
    "process_role_data(support_divided, support_outlier_kmean, metrics_after_correlation['support'], thresholds)\n",
    "process_role_data(mid_divided, mid_outlier_kmean, metrics_after_correlation['mid'], thresholds)\n",
    "process_role_data(top_divided, top_outlier_kmean, metrics_after_correlation['top'], thresholds)\n",
    "process_role_data(jungle_divided, jungle_outlier_kmean, metrics_after_correlation['jungle'], thresholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the z-score distribution for normal data detected by isolation forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_role_data(adc_divided, adc_normal, metrics_after_correlation['adc'], thresholds)\n",
    "process_role_data(support_divided, support_normal, metrics_after_correlation['support'], thresholds)\n",
    "process_role_data(mid_divided, mid_normal, metrics_after_correlation['mid'], thresholds)\n",
    "process_role_data(top_divided, top_normal, metrics_after_correlation['top'], thresholds)\n",
    "process_role_data(jungle_divided, jungle_normal, metrics_after_correlation['jungle'], thresholds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
